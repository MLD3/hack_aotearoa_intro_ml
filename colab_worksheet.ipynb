{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workshop_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mld3/hack_aotearoa_intro_ml/blob/master/colab_worksheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NPOYJ4hihiLq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "Check scikit-learn version, install tqdm if necessary, load useful packages."
      ]
    },
    {
      "metadata": {
        "id": "YM1aof5qhiMR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7ZAhY5mPNdT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/My Drive/Hack_Aotearoa/helper_colab.py\") as f:\n",
        "    with open(\"helper_colab.py\", \"w\") as f1:\n",
        "        for line in f:\n",
        "            f1.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95J37QpAFXoq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from helper_colab import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5A8Neq4hiMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1 - Feature extraction"
      ]
    },
    {
      "metadata": {
        "id": "6Y2ToSmChiMg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1a)\n",
        "Study generate feature vector(df) in the helper.py file. The input to this function is a pd.DataFrame containing the data for a single patient admission. The output is a python dictio- nary object, corresponding to a d-dimensional feature vector for this patient (with missing values). The keys of this dictionary are feature names, and the values are the corresponding feature values. For the time-invariant variables, we use the raw values. We replace unknown observations (−1) with unde- fined (use np.nan), and name these features with the original variable names. For each time-varying variable, we compute the mean of all measurements for that variable.\n",
        "\n",
        "(i) Read the [documentation](https://physionet.org/challenge/2012/\\#general-descriptors) on the variable ICUType, and reflect on the current feature representation of this variable.**What does such a representation imply, when using a linear classifier? How else might you represent this variable (as possibly more than one feature)?**\n",
        "\n",
        "(ii) Here we only consider the mean of the numerical variables. **What limitations are associated with this representation? What other summary statistics could be useful?**\n",
        "\n",
        "\n",
        "\n",
        "### 1b)\n",
        "Study impute missing values(X). Given a feature matrix X (where each row corresponds to a patient admission and each column a feature) with missing values, we consider each feature column independently. For each column, we impute the missing values by replacing it with the mean value of the observed values in that column.**What assumptions does this imputation approach make? How else might you handle missing data?**\n",
        "\n",
        "### 1c)\n",
        "Notice that many of these feature values lie on very different scales. To address this, we normalize each feature column xd to have range between 0 and 1. **Why might it be useful to scale the features in this way?**"
      ]
    },
    {
      "metadata": {
        "id": "onrzkSvihiMj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1d)\n",
        "Review the implementation of get train test split(). This helper function uses the three functions described above. First, it generates a feature vector for each patient, then aggregates them into a feature matrix (features are sorted alphabetically by name), and lastly performs imputation and normal- ization with respect to the population. After all these steps, it splits the data into 80% train and 20% test. **Report (i) the dimensionality $d$ of feature vector (ii) the average feature vector, and the corresponding name for each feature of the training set.**"
      ]
    },
    {
      "metadata": {
        "id": "CJzZtq3ehiMo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test, feature_names = get_train_test_split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xfe4SbuxhiMz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Dimensionality:\")\n",
        "print(f\"d = {X_train.shape[1]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCHS8Xh1hiNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Average feature vector:\")\n",
        "print(pd.DataFrame({\"Feature Name\": feature_names, \"Mean value\": X_train.mean(axis=0)}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdFTrKrKhiNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2 - Hyperparameter and model selection"
      ]
    },
    {
      "metadata": {
        "id": "Gfxt9TVbhiNS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Linear-kernel SVM"
      ]
    },
    {
      "metadata": {
        "id": "UOkxk7DfhiNT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1a\n",
        "\n",
        "To begin, complete the implementation of the function cv\\_performance(clf, X, y, metric=\\textquotesingle accuracy\\textquotesingle, k=5) as defined in the skeleton code. Here, you will make use of fit(X,y)  in the SVC class. The function returns the mean $k$-fold CV performance for the performance metric passed into the function. You should make use of the performance function in helper.py. When dividing the data into folds for CV, we use StratifiedKFold to try to keep the class proportions (ratio of positive to negative labels) roughly the same across folds. **Why might it be beneficial to maintain class proportions across folds?**"
      ]
    },
    {
      "metadata": {
        "id": "otsPo0AzhiNU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cv_performance(clf, X, y, metric='auroc', k=5):\n",
        "    \"\"\"\n",
        "    Splits the data X and the labels y into k-folds and runs k-fold\n",
        "    cross-validation: for each fold i in 1...k, trains a classifier on\n",
        "    all the data except the ith fold, and tests on the ith fold.\n",
        "    Calculates the k-fold cross-validation performance metric for classifier\n",
        "    clf by averaging the performance across folds.\n",
        "    Input:\n",
        "        clf: an instance of SVC()\n",
        "        X: (n,d) array of feature vectors, where n is the number of examples\n",
        "           and d is the number of features\n",
        "        y: (n,) array of binary labels {1,-1}\n",
        "        k: an int specifying the number of folds (default=5)\n",
        "        metric: string specifying the performance metric (default='auroc'\n",
        "             other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
        "             and 'specificity')\n",
        "    Returns:\n",
        "        average 'validation' performance across the k folds as np.float64\n",
        "    \"\"\"\n",
        "    # TODO: Finish implementing this function\n",
        "    skf = StratifiedKFold(n_splits=k)\n",
        "    scores = []\n",
        "    # For each split in the k folds...\n",
        "    for train, val in skf.split(X,y):\n",
        "    # Fit the data to the training data...\n",
        "        X_train, y_train, X_val, y_val = X[train], y[train], X[val], y[val]\n",
        "        # Fit the data to the training data...\n",
        "        clf.fit(X_train,y_train)\n",
        "        # And test on the val fold.\n",
        "        score = performance(clf, X_val, y_val, metric)\n",
        "        scores.append(score)\n",
        "\n",
        "    # And return the average performance across all fold splits.\n",
        "    return np.array(scores).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oj8UwrnWhiNb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1b\n",
        "Now implement the select param linear(X, y, metric='accuracy', k=5, C range=[]) function to choose a value of C for a linear SVM, using 5-fold cross validation on the training data maximizing AUROC. This function should call the cv performance function that you implemented in part(a), passing in instances of SVC(kernel='linear', C=C).\n"
      ]
    },
    {
      "metadata": {
        "id": "9DW-InkchiNh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def select_param_linear(X, y, metric='auroc', k=5, C_range = []):\n",
        "    \"\"\"\n",
        "    Sweeps different settings for the hyperparameter of a linear-kernel SVM,\n",
        "    calculating the k-fold CV performance for each setting on X, y.\n",
        "    Input:\n",
        "        X: (n,d) array of feature vectors, where n is the number of examples\n",
        "        and d is the number of features\n",
        "        y: (n,) array of binary labels {1,-1}\n",
        "        k: int specifying the number of folds (default=5)\n",
        "        metric: string specifying the performance metric (default='accuracy',\n",
        "             other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
        "             and 'specificity')\n",
        "        C_range: an array with C values to be searched over\n",
        "    Returns:\n",
        "        The parameter value for a linear-kernel SVM that maximizes the\n",
        "        average 5-fold CV performance.\n",
        "    \"\"\"\n",
        "    # TODO: Finish implementing this function\n",
        "    #HINT: You should be using your cv_performance function here\n",
        "    #to evaluate the performance of each SVM\n",
        "    print(\"Linear SVM Hyperparameter Selection based on %s:\" %metric)\n",
        "    scores = []\n",
        "    # Iterate over all of the given c parameters...\n",
        "    for c in C_range:\n",
        "        #Calculate the average performance on k-fold cross-validation\n",
        "        clf = get_classifier(kernel='linear', C=c)\n",
        "        score = cv_performance(clf, X, y, metric, k)\n",
        "        print(\"C: %.3f score: %.4f\" % (c, score))\n",
        "        scores.append((c, score))\n",
        "        \n",
        "    # Return the C value with the maximum score\n",
        "    maxval = max(scores, key=lambda x: x[1])\n",
        "    return maxval[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p070mOFLhiNo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1c\n",
        "\n",
        "Finally, using the training data and the functions implemented above, find the best setting for C (searching over a range of values for C chosen in powers of 10 between $10^{-2}$ and $10^2$)"
      ]
    },
    {
      "metadata": {
        "id": "JTvXRsLbhiNq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_C = select_param_linear(X_train, y_train, 'auroc', 5, np.logspace(-2, 2, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjniJ-dJhiNy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f\"Performance against C increases then decreases. Best C is {best_C:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3-MhSv97hiOB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1d\n",
        "Now, using the value of C that maximizes your chosen performance measure, create an SVM as in the previous question. Train this SVM on the training data X_train, y_train. **Report the performance of this SVM on the test data X_test, y_test and plot the ROC curve (you may use the plot ROC curve function in helper.py)**"
      ]
    },
    {
      "metadata": {
        "id": "c_LQjP7oNrGS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_clf = get_classifier(C=best_C)\n",
        "linear_clf.fit(X_train, y_train)\n",
        "test_perf = performance(linear_clf, X_test, y_test, 'auroc')\n",
        "print(f\"Test performance is {test_perf:.4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F9NK4wYIhiOW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_ROC_curve(linear_clf, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OLbPgHqahiOi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1e\n",
        "\n",
        "Recall that each coefficient of \\theta is associated with a clinical feature in your feature vector. The more positive a coefficient is, the more that feature contributes to a positive label. Similarly, the more negative a coefficient is, the more that feature contributes to a negative label. By examining these coefficients, we can start to generate hypotheses regarding what features are associated with increased (or decreased) risk of in-hospital mortality. Using C = 1.0, train an SVM on X train, y train. On this trained SVM, rank the features by their coefficients (hint: use coef [0] attribute of your classifier to obtain the learned coefficients. **Do these feature weights make sense?**"
      ]
    },
    {
      "metadata": {
        "id": "ro9N4pgjhiOk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "linear_clf = get_classifier(C=1)\n",
        "linear_clf.fit(X_train, y_train)\n",
        "weights = pd.DataFrame({'feature_name': feature_names, 'weight': linear_clf.coef_[0]})\n",
        "print(f\"Features ranked per coefficient:\")\n",
        "print(weights.sort_values(by='weight', ascending=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BDnpGzE1hiO2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.2 - RBF-kernel SVM\n",
        "\n",
        "Now, we will perform hyperparameter selection for an RBF-kernel SVM. "
      ]
    },
    {
      "metadata": {
        "id": "jTe0wxLshiO5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2a\n",
        "\n",
        "Implement the select param rbf(X, y, metric='accuracy', k=5, param range=[]) function to choose a setting for C and \" similar to the previous part. Your function should call your CV function (implemented earlier) passing in instances of SVC(kernel='rbf', C=C, gamma=gamma), with different values for C and \". Again, you may choose to use the helper function get classifier. Your function will perform a Grid Search over possible combinations of (C, \") and choose the best setting after tuning. The function argument param range is a two-column matrix, where the first column contains values of C and the second column contains values of \". Each row of this matrix is a distinct (C, \") pair to try."
      ]
    },
    {
      "metadata": {
        "id": "0L8gIj6uhiO6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def select_param_rbf(X, y, metric='auroc', k=5, param_range=[]):\n",
        "    \"\"\"\n",
        "    Sweeps different settings for the hyperparameters of an RBF-kernel SVM,\n",
        "    calculating the k-fold CV performance for each setting on X, y.\n",
        "    Input:\n",
        "        X: (n,d) array of feature vectors, where n is the number of examples\n",
        "           and d is the number of features\n",
        "        y: (n,) array of binary labels {1,-1}\n",
        "        k: an int specifying the number of folds (default=5)\n",
        "        metric: string specifying the performance metric (default='accuracy'\n",
        "                 other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
        "                 and 'specificity')\n",
        "        parameter_values: a (num_param, 2)-sized array containing the\n",
        "            parameter values to search over. The first column should\n",
        "            represent the values for C, and the second column should\n",
        "            represent the values for gamma. Each row of this array thus\n",
        "            represents a pair of parameters to be tried together.\n",
        "    Returns:\n",
        "        The parameter value(s) for a RBF-kernel SVM that maximize\n",
        "        the average 5-fold CV performance\n",
        "    \"\"\"\n",
        "    # TODO: Finish implementing this function\n",
        "    # Hint: This will be very similar to select_param_linear, except\n",
        "    # the type of SVM model you are using will be different...\n",
        "    print(\"RBF SVM Hyperparameter Selection based on %s:\" %metric)\n",
        "    scores = []\n",
        "    # For each parameter pair to try...\n",
        "    for p in param_range:\n",
        "        c= p[0]\n",
        "        gamma = p[1]\n",
        "        clf = get_classifier(kernel='rbf', C=c, gamma=gamma)\n",
        "        # Determine the performance of the defined SVM\n",
        "        score = cv_performance(clf, X, y, metric, k)\n",
        "        print(\"C: %.3f gamma: %.3f score: %.4f\" % (c, gamma, score))\n",
        "        scores.append((c, gamma, score))\n",
        "    # And report the pair (C,gamma) that yielded the best metric performance\n",
        "    maxval = max(scores, key=lambda x: x[2])\n",
        "    return maxval[0], maxval[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfUm6fnbhiO9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2b\n",
        "\n",
        "Using the training data the function implemented in (a), find the best values for C and \" for AUROC using Grid Search and 5-fold cross validation. Search over powers of 10 for both C (between $10^{−2}$ and $10^2$) and \\gamma (between $10^{−2}$ and $10^2$) [a total of 25 pairs]. **What setting maximizes cross-validation AUROC?** "
      ]
    },
    {
      "metadata": {
        "id": "zq-EoNuUhiPD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fjS2vt6hiPL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "C_range = np.logspace(-2, 2, 5)\n",
        "coeff_range = list(np.logspace(-2, 2, 5))\n",
        "param_range = list(itertools.product(C_range, coeff_range))\n",
        "best_C, best_gamma = select_param_rbf(X_train, y_train, 'auroc', 5, param_range)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LCHnJuYAhiPW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f\"The best pair of parameters is (C, gamma) = ({best_C:.6f}, {best_gamma:.5f})\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lf1jfrTQL1iE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using this setting, train a classifier using all of the training data and report performance on the test set. **How does it’s performance compare to the linear classifier you trained earlier?**"
      ]
    },
    {
      "metadata": {
        "id": "oobf_jtXhiPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rbf_clf = get_classifier(kernel='rbf', C=best_C, gamma=best_gamma)\n",
        "rbf_clf.fit(X_train, y_train)\n",
        "test_perf = performance(rbf_clf, X_test, y_test, \"auroc\")\n",
        "print(f\"Test performance is {test_perf:.4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HwDkgrYKhiPp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_ROC_curve(rbf_clf, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
